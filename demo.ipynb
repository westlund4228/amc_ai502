{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOtx7YzI9mG5",
        "outputId": "a5a73510-cf4c-45de-b4b5-a1c207b2a5b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'amc_ai502'...\n",
            "remote: Enumerating objects: 31, done.\u001b[K\n",
            "remote: Counting objects: 100% (31/31), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 31 (delta 2), reused 31 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (31/31), 42.31 KiB | 2.64 MiB/s, done.\n",
            "Resolving deltas: 100% (2/2), done.\n",
            "/content/amc_ai502\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/westlund4228/amc_ai502.git\n",
        "%cd amc_ai502"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX torch-pruning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_F-r0XkS_H2S",
        "outputId": "ca6f8f8f-6a1b-4c55-a785-30549b29d56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting torch-pruning\n",
            "  Downloading torch_pruning-1.5.2-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from torch-pruning) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->torch-pruning)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->torch-pruning)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->torch-pruning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->torch-pruning) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->torch-pruning) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->torch-pruning) (3.0.2)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_pruning-1.5.2-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.1/64.1 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m116.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch-pruning\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 tensorboardX-2.6.2.2 torch-pruning-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=256 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=2 \\\n",
        "    --lr=0.05 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --seed=2025 \\\n",
        "    --data_root=./data\n"
      ],
      "metadata": {
        "id": "OvTF20YdAPg9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/download_mobilenet_weights.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWdI7Qi4PJWY",
        "outputId": "e49cbe87-e39a-4921-fdf6-752e1cd662c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved to models/state_dict/mobilenetv1_cifar.pth.tar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=train \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.99 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --lbound=0.95 \\\n",
        "    --rbound=1 \\\n",
        "    --train_episode=4 \\\n",
        "    --reward=acc_reward \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --seed=2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XNF8Y_PASHB",
        "outputId": "a7f098ab-0fea-48e7-9f25-d4516092cb31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from /content/amc2/models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "DEBUG: train/val overlap size: 0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 97.860%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "=> Saving logs to ./logs/mobilenet_cifar_cifar10_r0.99_search-run3\n",
            "=> Output path: ./logs/mobilenet_cifar_cifar10_r0.99_search-run3...\n",
            "** Actual replay buffer size: 900\n",
            "\u001b[92m New best reward: 0.9588, acc: 95.8800, compress: 0.9099\u001b[00m\n",
            "\u001b[92m New best policy: [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [487, 487, 487, 244, 244, 122, 122, 61, 31]\u001b[00m\n",
            "#0: episode_reward:0.9588 acc: 95.8800, ratio: 0.9099\n",
            "\u001b[92m New best reward: 0.9610, acc: 96.1000, compress: 0.9116\u001b[00m\n",
            "\u001b[92m New best policy: [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.9657250372901276, 0.95, 0.95]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [487, 487, 487, 244, 244, 122, 124, 61, 31]\u001b[00m\n",
            "#1: episode_reward:0.9610 acc: 96.1000, ratio: 0.9116\n",
            "\u001b[92m New best reward: 0.9614, acc: 96.1400, compress: 0.9122\u001b[00m\n",
            "\u001b[92m New best policy: [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.9995041403160194, 0.95]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [487, 487, 487, 244, 244, 122, 122, 63, 31]\u001b[00m\n",
            "#2: episode_reward:0.9614 acc: 96.1400, ratio: 0.9122\n",
            "#3: episode_reward:0.9564 acc: 95.6400, ratio: 0.9165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dict/mobilenetv1_cifar.pth.tar \\\n",
        "    --n_calibration_batches=25 \\\n",
        "    --policy_path=./logs/mobilenet_cifar_cifar10_r0.99_search-run3/best_policy.txt \\\n",
        "    --export_path=./checkpoints/mobilenet_export.pt \\\n",
        "    --seed=2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iiqil6wKstV",
        "outputId": "2798d81e-1545-4df4-8a4d-4303edb842d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dict/mobilenetv1_cifar.pth.tar...\n",
            "=> Preparing data: cifar10...\n",
            "DEBUG: train/val overlap size: 0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> shape of embedding (n_layer * n_dim): (9, 10)\n",
            "=> original acc: 100.000%\n",
            "=> original weight size: 0.8118 M param\n",
            "=> original FLOPs: 15.1685 M\n",
            "=> Original model channels: [512, 512, 512, 256, 256, 128, 128, 64, 32]\n",
            "=> Pruning with ratios: [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.9995041403160194, 0.95]\n",
            "=> Channels after pruning: [486, 486, 486, 243, 243, 122, 122, 64, 30]\n",
            "\u001b[92m New best reward: 0.9998, acc: 99.9800, compress: 0.9122\u001b[00m\n",
            "\u001b[92m New best policy: [0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.95, 0.9995041403160194, 0.95]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [487, 487, 487, 244, 244, 122, 122, 63, 31]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=256 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=2 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/mobilenet_export.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7WemAg8Kopu",
        "outputId": "36ecd5df-bd57-4655-ae03-313735f9f5bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Preparing data..\n",
            "=> Preparing data..\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_export.pt...\n",
            "=> Model Parameter: 0.737 M, FLOPs: 13.605M\n",
            "=> Building model..\n",
            "=> Loading checkpoint from ./checkpoints/mobilenet_export.pt...\n",
            "=> Resuming from checkpoint..\n",
            "Using SGD...\n",
            "weight decay  = 4e-05\n",
            "=> Start training...\n",
            "Training mobilenet_cifar on cifar10...\n",
            "=> Saving logs to ./logs/mobilenet_cifar_cifar10_finetune-run4\n",
            "=> lr: 0.005\n",
            "\n",
            "Epoch: 0\n",
            " [=======================================>]  Step: 270ms | Tot: 43s697ms | Loss: 0.116 | Acc1: 95.936% | Acc5: 99.986% 196/196 \n",
            " [=======================================>]  Step: 42ms | Tot: 2s180ms | Loss: 0.540 | Acc1: 86.290% | Acc5: 99.320% 40/40 \n",
            "Current best acc: 86.29\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_cifar10_finetune-run4/ckpt.pth.tar\n",
            "=> lr: 0.0025\n",
            "\n",
            "Epoch: 1\n",
            " [=======================================>]  Step: 12ms | Tot: 45s80ms | Loss: 0.105 | Acc1: 96.406% | Acc5: 99.986% 196/196 \n",
            " [=======================================>]  Step: 3ms | Tot: 2s92ms | Loss: 0.532 | Acc1: 86.450% | Acc5: 99.320% 40/40 \n",
            "Current best acc: 86.45\n",
            "=> Saving checkpoint to ./logs/mobilenet_cifar_cifar10_finetune-run4/ckpt.pth.tar\n",
            "=> Model Parameter: 0.737 M, FLOPs: 13.605M, best top-1 acc: 86.45%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ResNet"
      ],
      "metadata": {
        "id": "Qb4Wm9xRLIC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Weights"
      ],
      "metadata": {
        "id": "iF8Nu4JKWA54"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python scripts/download_resnet_weights.py --model resnet18"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud-3g0HpvAFA",
        "outputId": "2dadc1d1-a0e6-452f-9fd8-87760259c02f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://rutgers.box.com/shared/static/gkw08ecs797j2et1ksmbg1w5t3idf5r5.zip\n",
            "100% 979M/979M [00:37<00:00, 25.9MB/s]\n",
            "Download complete.\n",
            "Extracting only state_dicts/resnet18.pt...\n",
            "Moved resnet18.pt to models/state_dicts/\n",
            "Removed zip and temp directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=train \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --preserve_ratio=0.95 \\\n",
        "    --acc_metric=acc1 \\\n",
        "    --lbound=0.9 \\\n",
        "    --rbound=1 \\\n",
        "    --train_episode=4 \\\n",
        "    --reward=acc_flops_reward \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dicts/resnet18.pt \\\n",
        "    --seed=2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxV75kNmQEG0",
        "outputId": "48ed6548-4d17-4b4c-ecba-5174a7a2d4c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dicts/resnet18.pt...\n",
            "=> Preparing data: cifar10...\n",
            "DEBUG: train/val overlap size: 0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 99.600%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "=> Saving logs to ./logs/resnet_cifar_cifar10_r0.95_search-run8\n",
            "=> Output path: ./logs/resnet_cifar_cifar10_r0.95_search-run8...\n",
            "** Actual replay buffer size: 1100\n",
            "\u001b[92m New best reward: -0.5022, acc: 97.3000, compress: 0.8485\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9193874567816488]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 116, 58, 58, 116, 116, 231, 231, 461, 471]\u001b[00m\n",
            "#0: episode_reward:-0.5022 acc: 97.3000, ratio: 0.8485\n",
            "\u001b[92m New best reward: -0.4466, acc: 97.6000, compress: 0.8562\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9085293082143958, 0.9, 0.9657250372901276, 0.9, 0.9, 0.9, 0.9, 0.9, 0.9]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 117, 58, 62, 116, 116, 231, 231, 461, 461]\u001b[00m\n",
            "#1: episode_reward:-0.4466 acc: 97.6000, ratio: 0.8562\n",
            "\u001b[92m New best reward: -0.3986, acc: 97.8600, compress: 0.8724\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9, 0.9995041403160194, 0.9, 0.9, 0.9572498787064212, 0.9, 0.9, 0.9, 0.9758796118925429]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 116, 63, 58, 116, 123, 231, 231, 461, 500]\u001b[00m\n",
            "#2: episode_reward:-0.3986 acc: 97.8600, ratio: 0.8724\n",
            "#3: episode_reward:-0.5021 acc: 97.3000, ratio: 0.8461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_search.py \\\n",
        "    --job=export \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./models/state_dicts/resnet18.pt \\\n",
        "    --n_calibration_batches=25 \\\n",
        "    --policy_path=./logs/resnet_cifar_cifar10_r0.95_search-run5/best_policy.txt \\\n",
        "    --export_path=./checkpoints/resnet_export.pt \\\n",
        "    --seed=2018"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsMA67UMjtRw",
        "outputId": "83bc2857-f4e4-4254-fc98-2073895978f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=> Building model..\n",
            "=> Loading checkpoint from ./models/state_dicts/resnet18.pt...\n",
            "=> Preparing data: cifar10...\n",
            "DEBUG: train/val overlap size: 0\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 16 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "=> shape of embedding (n_layer * n_dim): (11, 10)\n",
            "=> original acc: 100.000%\n",
            "=> original weight size: 11.1740 M param\n",
            "=> original FLOPs: 140.8481 M\n",
            "=> Original model channels: [512, 256, 128, 64, 64, 128, 128, 256, 256, 512, 512]\n",
            "=> Pruning with ratios: [0.9, 0.9, 0.9, 0.9995041403160194, 0.9, 0.9, 0.9572498787064212, 0.9, 0.9, 0.9, 0.9758796118925429]\n",
            "=> Channels after pruning: [461, 230, 115, 64, 58, 115, 123, 230, 230, 461, 500]\n",
            "\u001b[92m New best reward: 1.0000, acc: 100.0000, compress: 0.8724\u001b[00m\n",
            "\u001b[92m New best policy: [0.9, 0.9, 0.9, 0.9995041403160194, 0.9, 0.9, 0.9572498787064212, 0.9, 0.9, 0.9, 0.9758796118925429]\u001b[00m\n",
            "\u001b[92m Channels after pruning: [461, 231, 116, 63, 58, 116, 123, 231, 231, 461, 500]\u001b[00m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=mobilenet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=256 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=2 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/mobilenet_export.pt"
      ],
      "metadata": {
        "id": "0GDv7s8-q1RM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python amc_fine_tune.py \\\n",
        "    --model=resnet_cifar \\\n",
        "    --dataset=cifar10 \\\n",
        "    --batch_size=256 \\\n",
        "    --n_worker=2 \\\n",
        "    --n_epoch=2 \\\n",
        "    --lr=0.005 \\\n",
        "    --lr_type=cos \\\n",
        "    --wd=4e-5 \\\n",
        "    --seed=2025 \\\n",
        "    --data_root=./data \\\n",
        "    --ckpt_path=./checkpoints/resnet_export.pt"
      ],
      "metadata": {
        "id": "KBaEkRp9l_O1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}